# README

## What I Learned

### Overview

During this project, I explored Spiking Neural Networks (SNNs) and Reinforcement Learning (RL). The main focus was to understand the basic principles behind these concepts and how they can be applied in machine learning.

### Spiking Neural Networks (SNNs)

- SNNs are different from traditional neural networks because they use discrete spikes to communicate information instead of continuous values.
- Neurons in SNNs fire only when their membrane potential reaches a certain threshold, similar to biological neurons.
- I learned about neuron models like Leaky Integrate-and-Fire (LIF) and the learning mechanism called Spike-Timing Dependent Plasticity (STDP).
- I practiced converting image data into spike trains and visualized how spikes behave over time.

### Reinforcement Learning (RL)

- RL is a learning method where an agent learns to make decisions by interacting with an environment and receiving rewards or penalties.
- The agent balances exploration (trying new actions) and exploitation (choosing the best-known actions) to improve performance.
- I implemented Q-learning, a value-based RL method, to teach an agent how to navigate an environment.
- I also applied ideas from SNNs to modify the learning process, combining brain-inspired learning with RL.

### Key Takeaways

- SNNs provide a more biologically plausible and energy-efficient way to process information.
- RL allows agents to learn from experience without explicit supervision.
- Understanding both SNNs and RL gave me insights into how adaptive intelligent systems can be designed.

### Conclusion

This project helped me understand the foundations of SNNs and RL, and how these approaches can work together to create smarter, more efficient AI systems.
